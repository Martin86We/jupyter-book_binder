{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d3c7d6-779a-437a-84b2-55cfdf0d28f9",
   "metadata": {},
   "source": [
    "# Neuronales Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d1ecb-511f-490b-b0f8-58fdc2c15d97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7faeb5b-b3cc-4319-8548-a50cbc5131ee",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6421, 28, 28, 1)\n",
      "6421\n",
      "(2753, 28, 28, 1)\n",
      "2753\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "from scipy.special import expit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load numpy array from npy file\n",
    "\n",
    "X_train=load('../01_Dataset/dataset_28x28/X_train.npy').astype(np.float32) * 1.0/255.0 # normalisieren\n",
    "y_train=load('../01_Dataset/dataset_28x28/y_train.npy')\n",
    "X_test=load('../01_Dataset/dataset_28x28/X_test.npy').astype(np.float32) * 1.0/255.0  # normalisieren\n",
    "y_test=load('../01_Dataset/dataset_28x28/y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(len(y_train))\n",
    "print(X_test.shape)\n",
    "print(len(y_test))\n",
    "\n",
    "# one-hot-encoding\n",
    "oh = OneHotEncoder()\n",
    "y_train_oh = oh.fit_transform(y_train.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abbea4-7415-4a8f-af21-04e3658d3725",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90016671-e95c-48c6-ac36-68e8c5eba084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label y_train: 1\n",
      "Label y_train (One-Hot-Encoded): [0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label check\n",
    "i=5\n",
    "print(\"Label y_train: \" + str(y_train[i]))\n",
    "print(\"Label y_train (One-Hot-Encoded): \" + str(y_train_oh[i]))\n",
    "plt.imshow(X_train[i],cmap='gray')\n",
    "plt.show\n",
    "\n",
    "# Kategorien:\n",
    "# 0: innensechskant\n",
    "# 1: philips\n",
    "# 2: pozidriv\n",
    "# 3: sechskant\n",
    "# 4: torx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b7e5c3-ee69-44ff-af6d-27f3119d32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "(2753, 784)\n",
      "[3 0 1 ... 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32).reshape(-1, 784) # reshape hier wegen label test\n",
    "X_test  = X_test.astype(np.float32).reshape(-1, 784) #\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc55d83-2114-49d4-9037-2f10d8df9ba6",
   "metadata": {},
   "source": [
    "## Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e9819b-ce02-46aa-ad4c-6d0f862af358",
   "metadata": {
    "tags": [
     "hide-input",
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.20232473665092626\n",
      "0.2026879767526335\n",
      "0.1914275335997094\n",
      "0.17689792953142028\n",
      "0.17580820922629858\n",
      "0.17108608790410462\n",
      "0.17253904831093353\n",
      "0.17653468942971304\n",
      "0.17835088993824919\n",
      "0.1787141300399564\n",
      "0.1808935706501998\n",
      "0.18307301126044315\n",
      "0.1848892117689793\n",
      "0.185978932074101\n",
      "0.18815837268434435\n",
      "0.1888848528877588\n",
      "0.1910642934980022\n",
      "0.19179077370141664\n",
      "0.1925172539048311\n",
      "0.1936069742099528\n",
      "0.19433345441336725\n",
      "0.19433345441336725\n",
      "0.19614965492190337\n",
      "0.19723937522702506\n",
      "0.19723937522702506\n",
      "0.1976026153287323\n",
      "0.2001452960406829\n",
      "0.20050853614239011\n",
      "0.20196149654921902\n",
      "0.20196149654921902\n",
      "0.2026879767526335\n",
      "0.20341445695604796\n",
      "0.20450417726116962\n",
      "0.20523065746458408\n",
      "0.20632037776970577\n",
      "0.20777333817653468\n",
      "0.20849981837994916\n",
      "0.20886305848165637\n",
      "0.20958953868507083\n",
      "0.20995277878677807\n",
      "0.21067925899019252\n",
      "0.21285869960043588\n",
      "0.21322193970214312\n",
      "0.21394841990555757\n",
      "0.21540138031238648\n",
      "0.21540138031238648\n",
      "0.21576462041409372\n",
      "0.21721758082092263\n",
      "0.21830730112604432\n",
      "0.21903378132945878\n",
      "0.22048674173628768\n",
      "0.22121322193970214\n",
      "0.22121322193970214\n",
      "0.22157646204140938\n",
      "0.22266618234653104\n",
      "0.22484562295677443\n",
      "0.22484562295677443\n",
      "0.22484562295677443\n",
      "0.22520886305848165\n",
      "0.22629858336360334\n",
      "0.2270250635670178\n",
      "0.2284780239738467\n",
      "0.2284780239738467\n",
      "0.2295677442789684\n",
      "0.23029422448238285\n",
      "0.2310207046857973\n",
      "0.23138394478750454\n",
      "0.23174718488921178\n",
      "0.23174718488921178\n",
      "0.232110424990919\n",
      "0.2335633853977479\n",
      "0.23428986560116236\n",
      "0.23501634580457684\n",
      "0.23537958590628405\n",
      "0.2357428260079913\n",
      "0.2361060661096985\n",
      "0.2371957864148202\n",
      "0.23755902651652744\n",
      "0.23792226661823465\n",
      "0.2382855067199419\n",
      "0.23901198692335635\n",
      "0.2408281874318925\n",
      "0.2411914275335997\n",
      "0.24155466763530695\n",
      "0.24155466763530695\n",
      "0.24155466763530695\n",
      "0.2411914275335997\n",
      "0.24155466763530695\n",
      "0.24191790773701416\n",
      "0.2426443879404286\n",
      "0.24337086814384307\n",
      "0.24300762804213585\n",
      "0.24337086814384307\n",
      "0.24446058844896476\n",
      "0.244823828550672\n",
      "0.244823828550672\n",
      "0.24518706865237921\n",
      "0.244823828550672\n",
      "0.24518706865237921\n",
      "0.24700326916091536\n",
      "0.2473665092626226\n",
      "0.24772974936432982\n",
      "0.24772974936432982\n",
      "0.2488194696694515\n",
      "0.24918270977115872\n",
      "0.2502724300762804\n",
      "0.2509989102796949\n",
      "0.2513621503814021\n",
      "0.2517253904831093\n",
      "0.2517253904831093\n",
      "0.2517253904831093\n",
      "0.25208863058481656\n",
      "0.25281511078823105\n",
      "0.2524518706865238\n",
      "0.2524518706865238\n",
      "0.25317835088993823\n",
      "0.25354159099164547\n",
      "0.25463131129676714\n",
      "0.2549945513984744\n",
      "0.2553577915001816\n",
      "0.25572103160188886\n",
      "0.2564475118053033\n",
      "0.2564475118053033\n",
      "0.2586269524155467\n",
      "0.25971667272066834\n",
      "0.2604431529240828\n",
      "0.2604431529240828\n",
      "0.26225935343261897\n",
      "0.26225935343261897\n",
      "0.2626225935343262\n",
      "0.2629858336360334\n",
      "0.26443879404286236\n",
      "0.26480203414456954\n",
      "0.26589175444969126\n",
      "0.26589175444969126\n",
      "0.26698147475481293\n",
      "0.26734471485652017\n",
      "0.26734471485652017\n",
      "0.2680711950599346\n",
      "0.2680711950599346\n",
      "0.2680711950599346\n",
      "0.26843443516164184\n",
      "0.2695241554667635\n",
      "0.2691609153650563\n",
      "0.2695241554667635\n",
      "0.26988739556847074\n",
      "0.270250635670178\n",
      "0.270250635670178\n",
      "0.2706138757718852\n",
      "0.2717035960770069\n",
      "0.27206683617871413\n",
      "0.2727933163821286\n",
      "0.2731565564838358\n",
      "0.2738830366872503\n",
      "0.2731565564838358\n",
      "0.2738830366872503\n",
      "0.2746095168906647\n",
      "0.2753359970940792\n",
      "0.2753359970940792\n",
      "0.278241917907737\n",
      "0.2789683981111515\n",
      "0.28078459861968763\n",
      "0.28223755902651654\n",
      "0.28296403922993096\n",
      "0.28223755902651654\n",
      "0.2826007991282238\n",
      "0.2826007991282238\n",
      "0.2826007991282238\n",
      "0.2833272793316382\n",
      "0.2840537595350527\n",
      "0.2855067199418816\n",
      "0.28586996004358883\n",
      "0.286233200145296\n",
      "0.286233200145296\n",
      "0.28732292045041774\n",
      "0.287686160552125\n",
      "0.28877588085724665\n",
      "0.2898656011623683\n",
      "0.2905920813657828\n",
      "0.29168180167090446\n",
      "0.2920450417726117\n",
      "0.2920450417726117\n",
      "0.29386124228114785\n",
      "0.2945877224845623\n",
      "0.29531420268797676\n",
      "0.2960406828913912\n",
      "0.29894660370504905\n",
      "0.29894660370504905\n",
      "0.29894660370504905\n",
      "0.2993098438067563\n",
      "0.3000363240101707\n",
      "0.30039956411187796\n",
      "0.3011260443152924\n",
      "0.3011260443152924\n",
      "0.3014892844169996\n",
      "0.30185252451870687\n",
      "0.30185252451870687\n",
      "0.30257900472212135\n",
      "0.3033054849255358\n",
      "0.303668725027243\n",
      "0.303668725027243\n",
      "0.303668725027243\n",
      "0.3033054849255358\n",
      "0.30403196512895025\n",
      "0.3047584453323647\n",
      "0.3047584453323647\n",
      "0.3051216854340719\n",
      "0.3051216854340719\n",
      "0.3051216854340719\n",
      "0.3051216854340719\n",
      "0.3051216854340719\n",
      "0.30657464584090083\n",
      "0.30802760624772973\n",
      "0.3076643661460225\n",
      "0.308390846349437\n",
      "0.3087540864511442\n",
      "0.30911732655285146\n",
      "0.30911732655285146\n",
      "0.30911732655285146\n",
      "0.31057028695968036\n",
      "0.31057028695968036\n",
      "0.3112967671630948\n",
      "0.31166000726480203\n",
      "0.31166000726480203\n",
      "0.31202324736650927\n",
      "0.3127497275699237\n",
      "0.31311296767163094\n",
      "0.3138394478750454\n",
      "0.3149291681801671\n",
      "0.3152924082818743\n",
      "0.3152924082818743\n",
      "0.316382128586996\n",
      "0.31674536868870323\n",
      "0.3174718488921177\n",
      "0.3185615691972394\n",
      "0.3192880494006538\n",
      "0.3192880494006538\n",
      "0.3200145296040683\n",
      "0.3200145296040683\n",
      "0.32037776970577553\n",
      "0.32074100980748277\n",
      "0.32110424990918995\n",
      "0.3221939702143117\n",
      "0.3229204504177261\n",
      "0.3229204504177261\n",
      "0.32328369051943334\n",
      "0.3236469306211406\n",
      "0.324373410824555\n",
      "0.32473665092626225\n",
      "0.32473665092626225\n",
      "0.324373410824555\n",
      "0.324373410824555\n",
      "0.324373410824555\n",
      "0.324373410824555\n",
      "0.324373410824555\n",
      "0.32473665092626225\n",
      "0.3250998910279695\n",
      "0.32582637123138397\n",
      "0.32691609153650564\n",
      "0.3272793316382129\n",
      "0.3280058118416273\n",
      "0.32836905194333454\n",
      "0.329095532146749\n",
      "0.32982201235016345\n",
      "0.3301852524518707\n",
      "0.3301852524518707\n",
      "0.33054849255357793\n",
      "0.3309117326552851\n",
      "0.3309117326552851\n",
      "0.33127497275699236\n",
      "0.3316382128586996\n",
      "0.33200145296040684\n",
      "0.3323646930621141\n",
      "0.3323646930621141\n",
      "0.33272793316382127\n",
      "0.3330911732655285\n",
      "0.33345441336723575\n",
      "0.333817653468943\n",
      "0.3345441336723574\n",
      "0.33490737377406465\n",
      "0.3352706138757719\n",
      "0.3352706138757719\n",
      "0.33490737377406465\n",
      "0.33563385397747914\n",
      "0.3359970940791863\n",
      "0.33636033418089356\n",
      "0.3367235742826008\n",
      "0.33781329458772247\n",
      "0.3381765346894297\n",
      "0.33853977479113695\n",
      "0.3389030148928442\n",
      "0.3396294950962586\n",
      "0.3403559752996731\n",
      "0.3403559752996731\n",
      "0.3403559752996731\n",
      "0.3403559752996731\n",
      "0.34071921540138034\n",
      "0.34144569560479476\n",
      "0.34144569560479476\n",
      "0.34217217580820924\n",
      "0.34253541590991643\n",
      "0.34289865601162367\n",
      "0.34289865601162367\n",
      "0.34253541590991643\n",
      "0.34253541590991643\n",
      "0.34289865601162367\n",
      "0.34362513621503815\n",
      "0.3443516164184526\n",
      "0.3447148565201598\n",
      "0.3454413367235743\n",
      "0.34653105702869597\n",
      "0.34653105702869597\n",
      "0.34725753723211045\n",
      "0.3483472575372321\n",
      "0.3483472575372321\n",
      "0.3483472575372321\n",
      "0.34871049763893935\n",
      "0.3490737377406466\n",
      "0.3490737377406466\n",
      "0.3490737377406466\n",
      "0.3494369778423538\n",
      "0.3494369778423538\n",
      "0.3494369778423538\n",
      "0.3494369778423538\n",
      "0.349800217944061\n",
      "0.349800217944061\n",
      "0.349800217944061\n",
      "0.3505266981474755\n",
      "0.3508899382491827\n",
      "0.3508899382491827\n",
      "0.3508899382491827\n",
      "0.35161641845259717\n",
      "0.35161641845259717\n",
      "0.3519796585543044\n",
      "0.3519796585543044\n",
      "0.3519796585543044\n",
      "0.3519796585543044\n",
      "0.35234289865601165\n",
      "0.35270613875771883\n",
      "0.3530693788594261\n",
      "0.35379585906284056\n",
      "0.35379585906284056\n",
      "0.35415909916454774\n",
      "0.35524881946966946\n",
      "0.35633853977479113\n",
      "0.3570650199782056\n",
      "0.3574282600799128\n",
      "0.3574282600799128\n",
      "0.35779150018162004\n",
      "0.35779150018162004\n",
      "0.35779150018162004\n",
      "0.3581547402833273\n",
      "0.3585179803850345\n",
      "0.3596077006901562\n",
      "0.3599709407918634\n",
      "0.36033418089357067\n",
      "0.36033418089357067\n",
      "0.36033418089357067\n",
      "0.36033418089357067\n",
      "0.36142390119869233\n",
      "0.3617871413003996\n",
      "0.362513621503814\n",
      "0.36287686160552124\n",
      "0.3632401017072285\n",
      "0.3636033418089357\n",
      "0.36396658191064296\n",
      "0.36396658191064296\n",
      "0.36432982201235015\n",
      "0.36578278241917905\n",
      "0.36650926262259353\n",
      "0.3668725027243008\n",
      "0.3668725027243008\n",
      "0.3668725027243008\n",
      "0.3668725027243008\n",
      "0.3668725027243008\n",
      "0.367235742826008\n",
      "0.36796222302942244\n",
      "0.3675989829277152\n",
      "0.36796222302942244\n",
      "0.3686887032328369\n",
      "0.3690519433345441\n",
      "0.3697784235379586\n",
      "0.36941518343625135\n",
      "0.3690519433345441\n",
      "0.3697784235379586\n",
      "0.3697784235379586\n",
      "0.3697784235379586\n",
      "0.3697784235379586\n",
      "0.3697784235379586\n",
      "0.3697784235379586\n",
      "0.3697784235379586\n",
      "0.37086814384308026\n",
      "0.3712313839447875\n",
      "0.37159462404649474\n",
      "0.37232110424990916\n",
      "0.37232110424990916\n",
      "0.37232110424990916\n",
      "0.3726843443516164\n",
      "0.37304758445332364\n",
      "0.3734108245550309\n",
      "0.3737740646567381\n",
      "0.3741373047584453\n",
      "0.3741373047584453\n",
      "0.3741373047584453\n",
      "0.37450054486015255\n",
      "0.3748637849618598\n",
      "0.37522702506356703\n",
      "0.37522702506356703\n",
      "0.37595350526698146\n",
      "0.3763167453686887\n",
      "0.37667998547039594\n",
      "0.37667998547039594\n",
      "0.3770432255721032\n",
      "0.3770432255721032\n",
      "0.37740646567381037\n",
      "0.37740646567381037\n",
      "0.37740646567381037\n",
      "0.3770432255721032\n",
      "0.3770432255721032\n",
      "0.37740646567381037\n",
      "0.3777697057755176\n",
      "0.3784961859789321\n",
      "0.3792226661823465\n",
      "0.3792226661823465\n",
      "0.37958590628405375\n",
      "0.37958590628405375\n",
      "0.379949146385761\n",
      "0.379949146385761\n",
      "0.379949146385761\n",
      "0.379949146385761\n",
      "0.38031238648746823\n",
      "0.3806756265891754\n",
      "0.38103886669088266\n",
      "0.3814021067925899\n",
      "0.3814021067925899\n",
      "0.3814021067925899\n",
      "0.3814021067925899\n",
      "0.38176534689429714\n",
      "0.38176534689429714\n",
      "0.38176534689429714\n",
      "0.38176534689429714\n",
      "0.38176534689429714\n",
      "0.38176534689429714\n",
      "0.3828550671994188\n",
      "0.3828550671994188\n",
      "0.3828550671994188\n",
      "0.3835815474028333\n",
      "0.3835815474028333\n",
      "0.3839447875045405\n",
      "0.3843080276062477\n",
      "0.3843080276062477\n",
      "0.38467126770795496\n",
      "0.3850345078096622\n",
      "0.38539774791136944\n",
      "0.38539774791136944\n",
      "0.3857609880130766\n",
      "0.3857609880130766\n",
      "0.3857609880130766\n",
      "0.3857609880130766\n",
      "0.3857609880130766\n",
      "0.38612422811478386\n",
      "0.3864874682164911\n",
      "0.3872139484199056\n",
      "0.3872139484199056\n",
      "0.3872139484199056\n"
     ]
    }
   ],
   "source": [
    "# Quelle: Jannis Seemann , Udemy-Kurs Deep Learning\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "for i in range(0, 500):\n",
    "    for j in range(0, len(X_train), 100):\n",
    "        model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    print(np.mean(y_test_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee28da-1f15-4af7-9be9-f5b8574ed567",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mehrere Ausgänge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c1e41c-3159-476d-9f75-bff398f0d130",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from numpy import load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = load('../01_Dataset/dataset_28x28/X_train.npy').astype(np.float32).reshape(-1, 784)*1.0/255.0\n",
    "y_train = load('../01_Dataset/dataset_28x28/y_train.npy').astype(np.int32)\n",
    "\n",
    "X_test=load('../01_Dataset/dataset_28x28/X_test.npy').astype(np.float32).reshape(-1, 784)*1.0/255.0\n",
    "y_test=load('../01_Dataset/dataset_28x28/y_test.npy').astype(np.int32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea1787ff-ec38-4ee2-b7ec-a3d8d77af7bd",
   "metadata": {
    "tags": [
     "hide-cell",
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5785 - accuracy: 0.2179\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.4458 - accuracy: 0.5010\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3253 - accuracy: 0.6337\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2080 - accuracy: 0.6566\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1071 - accuracy: 0.6753\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0270 - accuracy: 0.6887\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9640 - accuracy: 0.7080\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9130 - accuracy: 0.7156\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8719 - accuracy: 0.7273\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8358 - accuracy: 0.7331\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8068 - accuracy: 0.7413\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7801 - accuracy: 0.7475\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7570 - accuracy: 0.7502\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7592\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7185 - accuracy: 0.7653\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.7670\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.7712\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7784\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.7782\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7835\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.7885\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7893\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.7893\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7929\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7969\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7974\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7986\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.8028\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.8008\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.8047\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.8055\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8081\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8050\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.8103\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.8123\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8145\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8123\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.8162\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8186\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8193\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8193\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8215\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8215\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8217\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8243\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8256\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8287\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8295\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8302\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8312\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.8313\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8327\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8341\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8341\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8346\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8354\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8366\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8391\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8387\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8399\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8405\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8416\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8424\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8415\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8455\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8430\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8438\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8439\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8438\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8463\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8464\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8471\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8478\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8464\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8471\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8483\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8486\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8506\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8491\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8517\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8505\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8524\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8488\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8524\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8541\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8522\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8519\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8527\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8544\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8527\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8556\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8552\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8544\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8547\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8541\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8556\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8564\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8558\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2721e1714c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(5, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6c2512-7d80-4629-ab6f-67a41dbf27a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8467\n",
      "[1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_440/1004372224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model.evaluate(X_test.reshape(-1, 784), y_test)\n",
    "model.predict(X_test.reshape(-1, 784))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(y_test[1])\n",
    "\n",
    "plt.imshow(X_test[1].reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "np.argmax(pred[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99cf323-5772-49fb-8b55-97227549243e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_440/1308905088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# wenn pozidriv vorhergesagt wurde und die richtige Klasse Philips gewesen ist:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# zeige die Bilder an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "\n",
    "# Kategorien:\n",
    "# 0: innensechskant\n",
    "# 1: philips\n",
    "# 2: pozidriv\n",
    "# 3: sechskant\n",
    "# 4: torx\n",
    "\n",
    "count=0\n",
    "for i in range(0, len(X_test)):\n",
    "    # wenn pozidriv vorhergesagt wurde und die richtige Klasse Philips gewesen ist:\n",
    "    if y_test_pred[i] == 2 and y_test[i] ==1:\n",
    "        count += 1\n",
    "        # zeige die Bilder an\n",
    "        plt.imshow(X_test[i].reshape(28, 28))\n",
    "        plt.show()\n",
    "        print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0ab014-96b6-41fa-9142-6a7ea574d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:57: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT0ElEQVR4nO3dcZBV5Znn8e+TRiAjJERERRoH2KWCuDGN6WINWBsMYQJqgn8kVbC6IcnuohmNGVxLMVZqM5XaKje7NZmixoQlO27MTnY0q3FlE1KOulKkYow2ozF2EGGUCR1QGbZE3JQRyLN/9IG5thf6Nve2l+73+6nquue85z3nPk839K/PObdvR2YiSSrXu9pdgCSpvQwCSSqcQSBJhTMIJKlwBoEkFW5Muws4GWeeeWbOmDGj3WVI0oiydevWf8jMKQPHR2QQzJgxg56ennaXIUkjSkT8fb1xLw1JUuEMAkkqnEEgSYUbkfcIJJXn0KFD9PX18cYbb7S7lFPe+PHj6ezs5LTTTmtovkEgaUTo6+tj4sSJzJgxg4hodzmnrMxk//799PX1MXPmzIb28dKQpBHhjTfeYPLkyYbAICKCyZMnD+nMySCQNGIYAo0Z6ufJIJCkwhkEktSA/fv309XVRVdXF+eccw7Tpk07tv7mm2+ecN+enh5uuOGGQZ9jwYIFrSp3SLxZLEkNmDx5Mk8//TQAX/3qV5kwYQI33XTTse2HDx9mzJj631K7u7vp7u4e9Dkee+yxltQ6VJ4RSNJJ+uxnP8uNN97IpZdeyi233MITTzzBggULmDdvHgsWLGD79u0AbN68mSuuuALoD5HPf/7zLFq0iFmzZrFu3bpjx5swYcKx+YsWLeJTn/oUc+bM4aqrruLoX5PctGkTc+bM4ZJLLuGGG244dtxmeEYgacT50//dy6/2vNbSY8499z38+09cMOT9nn/+eR5++GE6Ojp47bXX2LJlC2PGjOHhhx/my1/+Mvfdd9/b9nnuued49NFHOXjwIO9///v5whe+8LbX/D/11FP09vZy7rnnsnDhQn7605/S3d3NNddcw5YtW5g5cyYrV6486X5rGQSS1IRPf/rTdHR0AHDgwAFWrVrFjh07iAgOHTpUd5/LL7+ccePGMW7cOM466yxefvllOjs73zJn/vz5x8a6urrYtWsXEyZMYNasWcd+P2DlypVs2LCh6R4MAkkjzsn85D5cTj/99GPLX/nKV7j00ku5//772bVrF4sWLaq7z7hx444td3R0cPjw4YbmHL081GreI5CkFjlw4ADTpk0D4Dvf+U7Ljz9nzhxeeOEFdu3aBcA999zTkuMaBJLUIjfffDO33norCxcu5MiRIy0//rvf/W6++c1vsnTpUi655BLOPvts3vve9zZ93BiuU43h1N3dnf5hGqks27Zt4/zzz293GW33+uuvM2HCBDKT6667jtmzZ7NmzZq3zav3+YqIrZn5ttexekYgSSPIt7/9bbq6urjgggs4cOAA11xzTdPH9GaxJI0ga9asqXsG0AzPCCSpcAaBJBXOIJCkwhkEklQ4bxZLUgP279/P4sWLAXjppZfo6OhgypQpADzxxBOMHTv2hPtv3ryZsWPHtu2tpk/EIJCkBgz2NtSD2bx5MxMmTDglg6All4YiYmlEbI+InRGxts72iIh11fZnIuKiAds7IuKpiPhhK+qRpHfC1q1b+chHPsKHPvQhPv7xj7N3714A1q1bx9y5c7nwwgtZsWIFu3btYv369XzjG9+gq6uLn/zkJ22u/K2aPiOIiA7gDmAJ0Ac8GREbM/NXNdOWAbOrj38OfKt6POpLwDbgPc3WI6kAP14LL/2ytcc85wOw7PaGp2cmX/ziF3nggQeYMmUK99xzD7fddht33nknt99+Oy+++CLjxo3j1VdfZdKkSVx77bVDPot4p7Ti0tB8YGdmvgAQEXcDy4HaIFgOfDf738/i8YiYFBFTM3NvRHQClwP/AbixBfVI0rD73e9+x7PPPsuSJUsAOHLkCFOnTgXgwgsv5KqrruLKK6/kyiuvbGOVjWlFEEwDdtes9/HWn/aPN2casBf4c+BmYOKJniQiVgOrAc4777ymCpY0wg3hJ/fhkplccMEF/OxnP3vbth/96Eds2bKFjRs38rWvfY3e3t42VNi4VtwjiDpjA9/Jru6ciLgCeCUztw72JJm5ITO7M7P76J16SWqXcePGsW/fvmNBcOjQIXp7e/n973/P7t27ufTSS/n617/Oq6++yuuvv87EiRM5ePBgm6uurxVB0AdMr1nvBPY0OGch8MmI2AXcDXw0Iv6qBTVJ0rB617vexb333sstt9zCBz/4Qbq6unjsscc4cuQIV199NR/4wAeYN28ea9asYdKkSXziE5/g/vvvPyVvFjf9NtQRMQZ4HlgM/AZ4EviXmdlbM+dy4HrgMvovG63LzPkDjrMIuCkzB/1LzL4NtVQe34Z6aIbyNtRN3yPIzMMRcT3wINAB3JmZvRFxbbV9PbCJ/hDYCfwW+FyzzytJao2W/EJZZm6i/5t97dj6muUErhvkGJuBza2oR5LUON9rSNKIMRL/omI7DPXzZBBIGhHGjx/P/v37DYNBZCb79+9n/PjxDe/jew1JGhE6Ozvp6+tj37597S7llDd+/Hg6Ozsbnm8QSBoRTjvtNGbOnNnuMkYlLw1JUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqXEuCICKWRsT2iNgZEWvrbI+IWFdtfyYiLqrGp0fEoxGxLSJ6I+JLrahHktS4poMgIjqAO4BlwFxgZUTMHTBtGTC7+lgNfKsaPwz8u8w8H7gYuK7OvpKkYdSKM4L5wM7MfCEz3wTuBpYPmLMc+G72exyYFBFTM3NvZv4tQGYeBLYB01pQkySpQa0IgmnA7pr1Pt7+zXzQORExA5gH/LwFNUmSGtSKIIg6YzmUORExAbgP+JPMfK3uk0SsjoieiOjZt2/fSRcrSXqrVgRBHzC9Zr0T2NPonIg4jf4Q+F5m/uB4T5KZGzKzOzO7p0yZ0oKyJUnQmiB4EpgdETMjYiywAtg4YM5G4DPVq4cuBg5k5t6ICOAvgW2Z+WctqEWSNERjmj1AZh6OiOuBB4EO4M7M7I2Ia6vt64FNwGXATuC3wOeq3RcC/wr4ZUQ8XY19OTM3NVuXJKkxkTnwcv6pr7u7O3t6etpdhiSNKBGxNTO7B477m8WSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBWuJUEQEUsjYntE7IyItXW2R0Ssq7Y/ExEXNbqvJGl4NR0EEdEB3AEsA+YCKyNi7oBpy4DZ1cdq4FtD2FeSNIzGtOAY84GdmfkCQETcDSwHflUzZznw3cxM4PGImBQRU4EZDezbMo9/898y8dVtw3FoSXpHHJx0Phf/8bdbesxWXBqaBuyuWe+rxhqZ08i+AETE6ojoiYieffv2NV20JKlfK84Ios5YNjinkX37BzM3ABsAuru7684ZTKtTVJJGg1YEQR8wvWa9E9jT4JyxDewrSRpGrbg09CQwOyJmRsRYYAWwccCcjcBnqlcPXQwcyMy9De4rSRpGTZ8RZObhiLgeeBDoAO7MzN6IuLbavh7YBFwG7AR+C3zuRPs2W5MkqXHR/0KekaW7uzt7enraXYYkjSgRsTUzuweO+5vFklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXBNBUFEnBERD0XEjurxfceZtzQitkfEzohYWzP+nyLiuYh4JiLuj4hJzdQjSRq6Zs8I1gKPZOZs4JFq/S0iogO4A1gGzAVWRsTcavNDwD/LzAuB54Fbm6xHkjREzQbBcuCuavku4Mo6c+YDOzPzhcx8E7i72o/M/JvMPFzNexzobLIeSdIQNRsEZ2fmXoDq8aw6c6YBu2vW+6qxgT4P/LjJeiRJQzRmsAkR8TBwTp1NtzX4HFFnLAc8x23AYeB7J6hjNbAa4LzzzmvwqSVJgxk0CDLzY8fbFhEvR8TUzNwbEVOBV+pM6wOm16x3AntqjrEKuAJYnJnJcWTmBmADQHd393HnSZKGptlLQxuBVdXyKuCBOnOeBGZHxMyIGAusqPYjIpYCtwCfzMzfNlmLJOkkNBsEtwNLImIHsKRaJyLOjYhNANXN4OuBB4FtwPczs7fa/y+AicBDEfF0RKxvsh5J0hANemnoRDJzP7C4zvge4LKa9U3Apjrz/mkzzy9Jap6/WSxJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuGaCoKIOCMiHoqIHdXj+44zb2lEbI+InRGxts72myIiI+LMZuqRJA1ds2cEa4FHMnM28Ei1/hYR0QHcASwD5gIrI2JuzfbpwBLg103WIkk6Cc0GwXLgrmr5LuDKOnPmAzsz84XMfBO4u9rvqG8ANwPZZC2SpJPQbBCcnZl7AarHs+rMmQbsrlnvq8aIiE8Cv8nMXwz2RBGxOiJ6IqJn3759TZYtSTpqzGATIuJh4Jw6m25r8DmizlhGxB9Ux/ijRg6SmRuADQDd3d2ePUhSiwwaBJn5seNti4iXI2JqZu6NiKnAK3Wm9QHTa9Y7gT3APwFmAr+IiKPjfxsR8zPzpSH0IElqQrOXhjYCq6rlVcADdeY8CcyOiJkRMRZYAWzMzF9m5lmZOSMzZ9AfGBcZApL0zmo2CG4HlkTEDvpf+XM7QEScGxGbADLzMHA98CCwDfh+ZvY2+bySpBYZ9NLQiWTmfmBxnfE9wGU165uATYMca0YztUiSTo6/WSxJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSpcZGa7axiyiNgH/P0QdjkT+IdhKudUU0qvpfQJ5fRaSp/Qvl7/MDOnDBwckUEwVBHRk5nd7a7jnVBKr6X0CeX0WkqfcOr16qUhSSqcQSBJhSslCDa0u4B3UCm9ltInlNNrKX3CKdZrEfcIJEnHV8oZgSTpOAwCSSrcqA+CiFgaEdsjYmdErG13PUMVEdMj4tGI2BYRvRHxpWr8jIh4KCJ2VI/vq9nn1qrf7RHx8ZrxD0XEL6tt6yIi2tHTiURER0Q8FRE/rNZHa5+TIuLeiHiu+tp+eDT2GhFrqn+3z0bEX0fE+NHSZ0TcGRGvRMSzNWMt6y0ixkXEPdX4zyNixrA1k5mj9gPoAP4OmAWMBX4BzG13XUPsYSpwUbU8EXgemAt8HVhbja8F/mO1PLfqcxwws+q/o9r2BPBhIIAfA8va3V+dfm8E/gfww2p9tPZ5F/BvquWxwKTR1iswDXgReHe1/n3gs6OlT+BfABcBz9aMtaw34I+B9dXyCuCeYeul3Z/MYf5CfRh4sGb9VuDWdtfVZE8PAEuA7cDUamwqsL1ej8CD1edhKvBczfhK4L+0u58BvXUCjwAf5R+DYDT2+Z7qG2QMGB9VvVZBsBs4AxgD/BD4o9HUJzBjQBC0rLejc6rlMfT/JnIMRx+j/dLQ0X+IR/VVYyNSdWo4D/g5cHZm7gWoHs+qph2v52nV8sDxU8mfAzcDv68ZG419zgL2Af+tugz2XyPidEZZr5n5G+A/A78G9gIHMvNvGGV9DtDK3o7tk5mHgQPA5OEoerQHQb3riCPy9bIRMQG4D/iTzHztRFPrjOUJxk8JEXEF8Epmbm10lzpjp3yflTH0X1L4VmbOA/4f/ZcRjmdE9lpdH19O/6WQc4HTI+LqE+1SZ+yU77NBJ9PbO9b3aA+CPmB6zXonsKdNtZy0iDiN/hD4Xmb+oBp+OSKmVtunAq9U48frua9aHjh+qlgIfDIidgF3Ax+NiL9i9PUJ/TX2ZebPq/V76Q+G0dbrx4AXM3NfZh4CfgAsYPT1WauVvR3bJyLGAO8F/u9wFD3ag+BJYHZEzIyIsfTfcNnY5pqGpHoFwV8C2zLzz2o2bQRWVcur6L93cHR8RfWKg5nAbOCJ6jT1YERcXB3zMzX7tF1m3pqZnZk5g/6v0//JzKsZZX0CZOZLwO6IeH81tBj4FaOv118DF0fEH1T1LQa2Mfr6rNXK3mqP9Sn6/08Mz5lQu2+2vAM3cy6j/5U2fwfc1u56TqL+S+g/HXwGeLr6uIz+a4WPADuqxzNq9rmt6nc7Na+uALqBZ6ttf8Ew3XhqQc+L+MebxaOyT6AL6Km+rv8LeN9o7BX4U+C5qsb/Tv+rZkZFn8Bf03/v4xD9P73/61b2BowH/iewk/5XFs0arl58iwlJKtxovzQkSRqEQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIK9/8BNwYen0pAJi0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "limits = [100, 1000, 3000, 9000, 10500]\n",
    "test_accs = []\n",
    "train_accs = []\n",
    "for limit in limits:\n",
    "    model = NeuralNetwork(0.25)\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        for j in range(0, limit, 100):\n",
    "           model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    test_acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    y_train_pred = model.predict(X_train / 255.)\n",
    "    y_train_pred = np.argmax(y_train_pred, axis=0)\n",
    "    train_acc = np.mean(y_train_pred == y_train)\n",
    "\n",
    "    test_accs.append(test_acc)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(limits, train_accs, label=\"Training\")\n",
    "plt.plot(limits, test_accs, label=\"Test\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33d8c11d-9da5-4ebd-8425-f3c3961ffee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:55: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "epochs = []\n",
    "costs = []\n",
    "accs = []\n",
    "\n",
    "for i in range(0, 50):\n",
    "    for j in range(0, 10500, 100):\n",
    "        model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "    cost = model.cost(model.predict(X_train), y_train_oh)\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    epochs.append(i + 1)\n",
    "    costs.append(cost)\n",
    "    accs.append(acc)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(epochs, costs, label=\"Kosten\")\n",
    "plt.plot(epochs, accs, label=\"Genauigkeit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86df009a-c291-44f7-b5dc-a48ced4a3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:52: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: 0.0\n",
      "600: 0.0\n",
      "700: 0.0\n",
      "800: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1, hidden_size = 100):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(hidden_size, 784)\n",
    "        self.w1 = np.random.randn(5, hidden_size)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "for hidden_size in [500, 600, 700, 800]:\n",
    "\n",
    "    model = NeuralNetwork(0.3, hidden_size)\n",
    "\n",
    "    for i in range(0, 25):\n",
    "        for j in range(0, 10500, 100):\n",
    "            model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "        # cost = model.cost(model.predict(X_train), y_train_oh)\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    print(str(hidden_size) + \": \" + str(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8270b69-d922-491c-83d2-bda21a90828e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
