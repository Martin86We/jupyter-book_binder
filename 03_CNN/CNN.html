
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Convolutional Neural Network &#8212; Anwendung neuronaler Netze in einem Sortierroboter</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://martin86we.github.io/Masterthesis_2022/03_CNN/CNN.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pooling Layer" href="Pooling.html" />
    <link rel="prev" title="Neuronales Netz" href="../02_NN/5_NN_28x28.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Anwendung neuronaler Netze in einem Sortierroboter</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_Intro/Deckblatt.html">
   <center>
    Masterarbeit
   </center>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Intro
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_Intro/Eigenst.html">
   Eidesstattliche Erklärung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_Intro/intro.html">
   Aufgabenstellung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_Intro/Nomenklatur.html">
   Nomenklatur
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_Intro/Einleitung.html">
   Einleitung
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dataset
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../01_Dataset/dataset_28x28.html">
   Datensatz 1 (Schraubenköpfe)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_Dataset/dataset_224x224.html">
   Datensatz 2 (Schrauben)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Net
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../02_NN/1_neuron.html">
   Einzelnes Neuron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_NN/2_logReg_learning.html">
   Logistische Regression (Funktionsweise)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_NN/3_logReg_28x28.html">
   Logistische Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_NN/4_NN_learning.html">
   Neuronales Netz (Funktionsweise)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_NN/5_NN_28x28.html">
   Neuronales Netz
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Net
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Convolutional Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pooling.html">
   Pooling Layer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CNN_1_28x28.html">
   CNN 1 (Schraubenköpfe)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CNN_2_224x224.html">
   CNN 2 (Schrauben)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/03_CNN/CNN.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Martin86We/Masterthesis_2022"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        <a class="edit-button" href="https://github.com/Martin86We/Masterthesis_2022/edit/main/03_CNN/CNN.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Martin86We/Masterthesis_2022/main?urlpath=tree/03_CNN/CNN.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/Martin86We/Masterthesis_2022/blob/main/03_CNN/CNN.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dimensionale-faltung">
   2-Dimensionale Faltung
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutional-neural-net-mit-keras">
   Convolutional Neural Net mit Keras
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Convolutional Neural Network</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dimensionale-faltung">
   2-Dimensionale Faltung
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutional-neural-net-mit-keras">
   Convolutional Neural Net mit Keras
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="convolutional-neural-network">
<span id="cnn"></span><h1>Convolutional Neural Network<a class="headerlink" href="#convolutional-neural-network" title="Permalink to this headline">¶</a></h1>
<p><strong>Weshalb Convolutional Neural Networks?</strong>
Das Hauptstrukturmerkmal von neuronalen Netzen ist, dass alle Neuronen miteinander verbunden sind. Wenn wir beispielsweise Bilder mit 28 x 28 Pixeln in Graustufen haben, haben wir am Ende 784 (28 x 28 x 1) Neuronen in einer Ebene, was überschaubar erscheint. Die meisten Bilder haben jedoch viel mehr Pixel und sind nicht grau skaliert. Unter der Annahme, dass eine Reihe von Farbbildern in 4K Ultra HD vorliegt, haben wir also 26.542.080 (4096 x 2160 x 3) verschiedene Neuronen, die in der ersten Schicht miteinander verbunden sind, was nicht wirklich handhabbar ist. Daher können wir sagen, dass neuronale Netze ohne Convolutional Layer, für die Bildklassifizierung nicht skalierbar sind. Insbesondere bei Bildern scheint es jedoch wenig Korrelation oder Beziehung zwischen zwei einzelnen Pixeln zu geben, es sei denn, sie liegen nahe beieinander. Dies führt zu der Idee von Convolutional Layers und Pooling Layers.</p>
<p>Ein Theorem aus dem Jahr 1988, das “Universal Approximation Theorem”, sagt, dass jede beliebige, glatte Funktion, durch ein NN mit nur einem Hidden Layer approximiert werden kann. Nach diesem Theorem, würde dieses einfache NN bereits in der Lage sein, jedes beliebige Bild bzw. die Funktion der Pixelwerte zu erlernen. Die Fehler und die lange Rechenzeit zeigen die Probleme in der Praxis. Denn um dieses Theorem zu erfüllen, sind für sehr einfache Netze unendlich viel Rechenleistung, Zeit und Trainingsbeispiele nötig. Diese stehen i.<span class="math notranslate nohighlight">\(~\)</span>d.<span class="math notranslate nohighlight">\(~\)</span>R. nicht zur Verfügung. Für die Bilderkennung haben sich CNNs als sehr wirksam erwiesen. Die Arbeitsweise soll in diesem Abschnitt erläutert werden.
Der Grundgedanke bei der Nutzung der Convolutional Layer ist, dem NN zusätzliches „Spezialwissen“  über die Daten zu geben. Das NN ist durch den zusätzlichen Convolutional Layer in der Lage, spezielle Bildelemente und Strukturen besser zu erkennen.</p>
<p>Es werden meist mehrere Convolutional Layer hintereinander geschalten. Das NN kann auf der ersten Ebene lernen, Kanten zu erkennen. Auf weiteren Ebenen lernt es dann weitere “Bild-Features” wie z.<span class="math notranslate nohighlight">\(~\)</span>B. Übergänge, Rundungen o.<span class="math notranslate nohighlight">\(~\)</span>ä. zu erkennen. Diese werden auf höheren Ebenen weiterverarbeitet.</p>
<p><strong>Beispiel einer einfachen 1D-Faltung:</strong></p>
<p>Die beiden einfachen Beispiele sollen die Berechnung verdeutlichen. Die Filterfunktion wird auf die Pixel gelegt und Elementweise multipliziert.
Im folgenden Beispiel werden 3 Pixel eines Bildes verwendet. Die Ergebnisse sagen etwas über den Bildinhalt aus:</p>
<ul class="simple">
<li><p>positives Ergebnis: Übergang von hell zu dunkel</p></li>
<li><p>negatives Ergebnis: Übergang von dunkel nach hell</p></li>
<li><p>neutrales Ergebnis: Übergang wechselnd, hell-dunkel-hell  oder dunkel-hell-dunkel</p></li>
</ul>
<div class="figure align-default" id="conv1d-fig">
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/cnn_1d.png"><img alt="conv1d" class="bg-primary mb-1" src="../_images/cnn_1d.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text">Eindimensionale Faltung</span><a class="headerlink" href="#conv1d-fig" title="Permalink to this image">¶</a></p>
</div>
<p>Da ein Bild aus mehr als 3 Pixel besteht, muss die Filterfunktion über das gesamte Bild „geschoben“ werden. Das folgende Beispiel demonstriert den Vorgang der Convolution im Fall eines eindimensionalen Filters. Der Filter besteht in diesem Fall wieder aus einem Zeilenvektor mit 3 Elementen. Der Filter wird nun Pixelweise über die Bildzeile geschoben, die Ergebnisse werden gespeichert und geben wiederum Aufschluss über die Bildstruktur.
Die Ergebnisse zeigen wieder die enthaltene Bildstruktur:</p>
<ul class="simple">
<li><p>1: hell-dunkel</p></li>
<li><p>0: hell-dunkel-hell</p></li>
<li><p>0: dunkel-hell-dunkel</p></li>
<li><p>1: hell-dunkel
–1: dunkel-hell</p></li>
</ul>
<div class="figure align-default" id="conv1d-fig2">
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/cnn_1d_long.png"><img alt="conv1d" class="bg-primary mb-1" src="../_images/cnn_1d_long.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 17 </span><span class="caption-text">Eindimensionale Faltung mit mehreren Übergängen</span><a class="headerlink" href="#conv1d-fig2" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="dimensionale-faltung">
<h2>2-Dimensionale Faltung<a class="headerlink" href="#dimensionale-faltung" title="Permalink to this headline">¶</a></h2>
<p>In der Praxis werden in der Bilderkennung 2-dimensionale Filter verwendet, ein häufig verwendetes Format ist ein 3x3 Filter. Der Vorgang ist analog zum eindimensionalen Fall, der Filter wird über das gesamte Bild geschoben. Das folgende Beispiel zeigt einen Filter, der in der Lage ist, senkrechte Kanten zu erkennen.</p>
<div class="figure align-default" id="markdown-fig">
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/cnn_2d_a.png"><img alt="cnn" class="bg-primary mb-1" src="../_images/cnn_2d_a.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 18 </span><span class="caption-text">Zweidimensionale Faltung Schrittweise</span><a class="headerlink" href="#markdown-fig" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id1">
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/cnn_2d_b.png"><img alt="cnn" class="bg-primary mb-1" src="../_images/cnn_2d_b.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 19 </span><span class="caption-text">Eindimensionale Faltung mit mehreren Übergängen</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Die Werte der Filter bilden die Gewichte des Convolutional Layer. Diese Gewichte werden durch das Training selbst bestimmt und somit ist das CNN in der Lage, sich selbstständig auf relevante Features wie z.<span class="math notranslate nohighlight">\(~\)</span>B. Kanten zu fokussieren.</p>
<p><strong>Im Folgenden noch weitere Ergebnisse für bestimmte Bildstrukturen:</strong></p>
<div class="figure align-default" id="id2">
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/cnn_2d_c.png"><img alt="pozi" class="bg-primary mb-1" src="../_images/cnn_2d_c.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 20 </span><span class="caption-text">Zweidimensionale Faltung einer einheitlichen Fläche</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id3">
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/cnn_2d_d.png"><img alt="pozi" class="bg-primary mb-1" src="../_images/cnn_2d_d.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 21 </span><span class="caption-text">Zweidimensionale Faltung horizontale Kante</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id4">
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/cnn_2d_e.png"><img alt="cnn" class="bg-primary mb-1" src="../_images/cnn_2d_e.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 22 </span><span class="caption-text">Zweidimensionale Faltung schräge Kante</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>Mit Hilfe der Convolutional-Layer bekommt das neuronale Netz ein „Verständnis“ über die Struktur der Bilder (Ecken, Kanten, usw.) „eingebaut“. Das CNN ist somit auf die Erkennung von Bildern spezialisiert und dementsprechend leistungsfähiger als ein NN ohne dieses Bildverständnis.</p>
<p>Die Filter oder Kernels gibt man nicht vor, sondern lässt die Werte vom Convolutional Layer ermitteln. Die Kernels werden dabei so bestimmt, dass sie für die Erkennung der Bilder am effektivsten sind.</p>
<p>Es sollen aber nicht nur vertikale Kanten gefunden werden, sondern auch schräge und waagerechte. Da jeder Filter für ein bestimmtes Feature zuständig ist, benötigt das CNN mehrere solcher Filter, um alle relevanten Zusammenhänge extrahieren zu können. Die Anzahl an Filtern bereitgestellt werden sollten, hängt von den Daten ab und ist ein Hyperparameter den man empirisch ermitteln muss.</p>
</div>
<div class="section" id="convolutional-neural-net-mit-keras">
<h2>Convolutional Neural Net mit Keras<a class="headerlink" href="#convolutional-neural-net-mit-keras" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Vorstellung: MNIST-Daten!</span>
<span class="c1"># http://yann.lecun.com/exdb/mnist/</span>
<span class="c1"># FashionMNIST: https://github.com/zalandoresearch/fashion-mnist</span>

<span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">load</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>


<span class="n">X_train</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s1">&#39;../02_NN/Dataset/X_train.npy&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="c1">#.reshape(-1, 784)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s1">&#39;../02_NN/Dataset/y_train.npy&#39;</span><span class="p">)</span>


<span class="c1">#oh = OneHotEncoder()</span>
<span class="c1">#y_train_oh = oh.fit_transform(y_train.reshape(-1, 1)).toarray()</span>

<span class="n">X_test</span><span class="o">=</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;../02_NN/Dataset/X_test.npy&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="c1">#.reshape(-1, 784)</span>
<span class="n">y_test</span><span class="o">=</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;../02_NN/Dataset/y_test.npy&#39;</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10500, 28, 28)
[[0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 ...
 [0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0.]]
</pre></div>
</div>
</div>
</div>
<p>Das Format der Daten (10500, 28, 28) passt noch nicht zum geforderten Eingangsformat und muss angepasst werden. Das CNN verlangt ein vierdimensionales Array (10500, 28, 28, 1) und dieses wird mit der <em>reshape</em>-Methode erzeugt (siehe model.fit() im nächsten Programm).</p>
<p><strong>Stochastic Gradient Descent</strong><br />
Das stochastische Gradientenabstiegsverfahren, wird mit <em>optimizer=”sgd”</em> ausgewählt.</p>
<div class="cell tag_scroll-output tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CNN!</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="c1">#model.add(Conv2D(32, kernel_size=(3, 3), activation=&quot;relu&quot;))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;sgd&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10500</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
21/21 [==============================] - 1s 22ms/step - loss: 229.5953 - accuracy: 0.3178
Epoch 2/20
21/21 [==============================] - 0s 21ms/step - loss: 0.9440 - accuracy: 0.6190
Epoch 3/20
21/21 [==============================] - 0s 21ms/step - loss: 0.6530 - accuracy: 0.7649
Epoch 4/20
21/21 [==============================] - 0s 21ms/step - loss: 0.5013 - accuracy: 0.8199
Epoch 5/20
21/21 [==============================] - 0s 22ms/step - loss: 0.4058 - accuracy: 0.8393
Epoch 6/20
21/21 [==============================] - 0s 22ms/step - loss: 0.4397 - accuracy: 0.8294
Epoch 7/20
21/21 [==============================] - 0s 22ms/step - loss: 0.3674 - accuracy: 0.8583
Epoch 8/20
21/21 [==============================] - 0s 22ms/step - loss: 0.3386 - accuracy: 0.8624
Epoch 9/20
21/21 [==============================] - 0s 22ms/step - loss: 0.3027 - accuracy: 0.8836
Epoch 10/20
21/21 [==============================] - 0s 24ms/step - loss: 0.3147 - accuracy: 0.8754
Epoch 11/20
21/21 [==============================] - 0s 22ms/step - loss: 0.2679 - accuracy: 0.8914
Epoch 12/20
21/21 [==============================] - 0s 22ms/step - loss: 0.2448 - accuracy: 0.9017
Epoch 13/20
21/21 [==============================] - 0s 22ms/step - loss: 0.2369 - accuracy: 0.9060
Epoch 14/20
21/21 [==============================] - 0s 22ms/step - loss: 0.2150 - accuracy: 0.9114
Epoch 15/20
21/21 [==============================] - 0s 22ms/step - loss: 0.3123 - accuracy: 0.8828
Epoch 16/20
21/21 [==============================] - 0s 22ms/step - loss: 0.2253 - accuracy: 0.9091
Epoch 17/20
21/21 [==============================] - 0s 22ms/step - loss: 0.1853 - accuracy: 0.9243
Epoch 18/20
21/21 [==============================] - 0s 22ms/step - loss: 0.1935 - accuracy: 0.9216
Epoch 19/20
21/21 [==============================] - 0s 22ms/step - loss: 0.1948 - accuracy: 0.9217
Epoch 20/20
21/21 [==============================] - 0s 22ms/step - loss: 0.1432 - accuracy: 0.9435
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f180005d790&gt;
</pre></div>
</div>
</div>
</div>
<p><strong>RMSprop</strong></p>
<p>Ein weiterer Optimizer ist der RMSprop. Dieser wird durch <em>optimizer=”rmsprop”</em> ausgewählt.</p>
<div class="cell tag_scroll-output tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CNN!</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10500</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
21/21 [==============================] - 1s 22ms/step - loss: 242.0397 - accuracy: 0.4830
Epoch 2/20
21/21 [==============================] - 0s 22ms/step - loss: 63.1420 - accuracy: 0.6419
Epoch 3/20
21/21 [==============================] - 0s 21ms/step - loss: 27.1203 - accuracy: 0.7310
Epoch 4/20
21/21 [==============================] - 0s 22ms/step - loss: 10.0603 - accuracy: 0.8360
Epoch 5/20
21/21 [==============================] - 0s 22ms/step - loss: 4.6834 - accuracy: 0.8353
Epoch 6/20
21/21 [==============================] - 0s 21ms/step - loss: 2.2660 - accuracy: 0.8735
Epoch 7/20
21/21 [==============================] - 0s 22ms/step - loss: 1.4034 - accuracy: 0.9078
Epoch 8/20
21/21 [==============================] - 0s 22ms/step - loss: 0.9845 - accuracy: 0.9339
Epoch 9/20
21/21 [==============================] - 0s 22ms/step - loss: 0.5971 - accuracy: 0.9523
Epoch 10/20
21/21 [==============================] - 0s 22ms/step - loss: 0.0607 - accuracy: 0.9875
Epoch 11/20
21/21 [==============================] - 0s 22ms/step - loss: 0.4934 - accuracy: 0.9664
Epoch 12/20
21/21 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 0.9981
Epoch 13/20
21/21 [==============================] - 0s 22ms/step - loss: 0.6108 - accuracy: 0.9581
Epoch 14/20
21/21 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 0.9998
Epoch 15/20
21/21 [==============================] - 0s 22ms/step - loss: 3.7297e-04 - accuracy: 1.0000
Epoch 16/20
21/21 [==============================] - 0s 22ms/step - loss: 0.4393 - accuracy: 0.9813
Epoch 17/20
21/21 [==============================] - 0s 22ms/step - loss: 5.3599e-04 - accuracy: 1.0000
Epoch 18/20
21/21 [==============================] - 0s 23ms/step - loss: 2.5452e-04 - accuracy: 1.0000
Epoch 19/20
21/21 [==============================] - 0s 22ms/step - loss: 0.3049 - accuracy: 0.9837
Epoch 20/20
21/21 [==============================] - 0s 23ms/step - loss: 4.4494e-04 - accuracy: 1.0000
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f17e27e5e50&gt;
</pre></div>
</div>
</div>
</div>
<p><strong>2 Convolutional Layer</strong></p>
<p>Einen weiteren Convolutional Layer verwenden:</p>
<div class="cell tag_scroll-output tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CNN!</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10500</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
21/21 [==============================] - 2s 96ms/step - loss: 21.6524 - accuracy: 0.6189
Epoch 2/20
21/21 [==============================] - 2s 95ms/step - loss: 0.8093 - accuracy: 0.8665
Epoch 3/20
21/21 [==============================] - 2s 95ms/step - loss: 0.4227 - accuracy: 0.8997
Epoch 4/20
21/21 [==============================] - 2s 94ms/step - loss: 0.1646 - accuracy: 0.9585
Epoch 5/20
21/21 [==============================] - 2s 98ms/step - loss: 0.0131 - accuracy: 0.9990
Epoch 6/20
21/21 [==============================] - 2s 96ms/step - loss: 0.2447 - accuracy: 0.9744
Epoch 7/20
21/21 [==============================] - 2s 96ms/step - loss: 0.0067 - accuracy: 0.9998
Epoch 8/20
21/21 [==============================] - 2s 95ms/step - loss: 0.0017 - accuracy: 1.0000
Epoch 9/20
21/21 [==============================] - 2s 118ms/step - loss: 0.0815 - accuracy: 0.9895
Epoch 10/20
21/21 [==============================] - 3s 127ms/step - loss: 0.0597 - accuracy: 0.9820
Epoch 11/20
21/21 [==============================] - 3s 127ms/step - loss: 0.0013 - accuracy: 1.0000
Epoch 12/20
21/21 [==============================] - 3s 126ms/step - loss: 3.9080e-04 - accuracy: 1.0000
Epoch 13/20
21/21 [==============================] - 3s 128ms/step - loss: 1.1759e-04 - accuracy: 1.0000
Epoch 14/20
21/21 [==============================] - 3s 127ms/step - loss: 0.0034 - accuracy: 0.9983
Epoch 15/20
21/21 [==============================] - 3s 126ms/step - loss: 0.1700 - accuracy: 0.9794
Epoch 16/20
21/21 [==============================] - 3s 125ms/step - loss: 2.5466e-04 - accuracy: 1.0000
Epoch 17/20
21/21 [==============================] - 3s 128ms/step - loss: 1.7362e-04 - accuracy: 1.0000
Epoch 18/20
21/21 [==============================] - 3s 132ms/step - loss: 6.7044e-05 - accuracy: 1.0000
Epoch 19/20
21/21 [==============================] - 3s 128ms/step - loss: 7.7813e-05 - accuracy: 1.0000
Epoch 20/20
21/21 [==============================] - 3s 132ms/step - loss: 0.0971 - accuracy: 0.9824
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f17e27a5150&gt;
</pre></div>
</div>
</div>
</div>
<p>Die Schraubenkopfbilder können vom CNN sehr gut gelernt werden. Die Trainingsgenauigkeit beträgt bis zu 100 %. Das war zu erwarten, da die Bilder recht einfach zu unterscheiden sind und für ein CNN kein Problem darstellen sollten.</p>
<p>Im nächsten Abschnitt wird der Datensatz mit den echten Bildern verwendet.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "Martin86We/Masterthesis_2022",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./03_CNN"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../02_NN/5_NN_28x28.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Neuronales Netz</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Pooling.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Pooling Layer</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Martin Weilepp<br/>
    
      <div class="extra_footer">
        <p>
HTWG Konstanz
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>